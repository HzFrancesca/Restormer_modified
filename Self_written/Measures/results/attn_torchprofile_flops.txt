开始计算 Attention 模块的 MACs 和参数数量...
输入张量形状: torch.Size([1, 8, 64, 96])
模块初始化参数: (8, 4, False)

--- 处理 HWxHW_Attention ---
  Macs: 757874704
  Params: 476
--------------------------------
--- 处理 CxC_Attention ---
  Macs: 3096608
  Params: 476
------------------------------
--- 处理 CHxCH_Attention ---
  Macs: 15548433
  Params: 476
--------------------------------
--- 处理 WxW_Attention ---
  Macs: 12374033
  Params: 476
------------------------------
--- 处理 CWxCW_Attention ---
  Macs: 21921809
  Params: 476
--------------------------------
--- 处理 HxH_Attention ---
  Macs: 9207825
  Params: 476
------------------------------
--- 处理 CNNxCNN_Attention ---
  Macs: 15548440
  Params: 476
----------------------------------
--- 处理 CxNNxNN_Attention ---
  Macs: 9224210
  Params: 476
----------------------------------
--- 处理 CxHxH_Attention ---
  Macs: 9224208
  Params: 476
--------------------------------
--- 处理 CxWxW_Attention ---
  Macs: 12410896
  Params: 476
--------------------------------
所有指定的 Attention 模块处理完成。
