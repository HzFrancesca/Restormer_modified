开始计算 Attention 模块的 MACs 和参数数量...
输入张量形状: torch.Size([1, 8, 64, 96])
模块初始化参数: (8, 4, False)

--- 处理 HWxHW_Attention ---
  Macs: 757874704
  Params: 476
--------------------------------
--- 处理 CxC_Attention ---
  Macs: 3096608
  Params: 476
------------------------------
--- 处理 CHxCH_Attention ---
  Macs: 15548433
  Params: 476
--------------------------------
--- 处理 WxW_Attention ---
  Macs: 12374033
  Params: 476
------------------------------
--- 处理 CWxCW_Attention ---
  Macs: 21921809
  Params: 476
--------------------------------
--- 处理 HxH_Attention ---
  Macs: 9207825
  Params: 476
------------------------------
--- 处理 CNNxCNN_Attention ---(N=4)
  Macs: 6049816
  Params: 476
----------------------------------
--- 处理 CxNNxNN_Attention ---(N=4)
  Macs: 4474898
  Params: 476
----------------------------------
--- 处理 CxHxH_Attention ---
  Macs: 9224208
  Params: 476
--------------------------------
--- 处理 CxWxW_Attention ---
  Macs: 12410896
  Params: 476
-------------------------------
